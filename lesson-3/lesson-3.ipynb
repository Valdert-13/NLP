{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\NLP\\lib\\site-packages\\tqdm\\std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import spacy\n",
    "import nltk\n",
    "import en_core_web_sm\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_sm\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('maxent_ne_chunker')\n",
    "# nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/tweet_data.pkl', 'rb') as f:\n",
    "    combine_df  = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when father is dysfunctional and is so selfish...</td>\n",
       "      <td>[when, father, is, dysfunctional, and, is, so,...</td>\n",
       "      <td>[father, dysfunctional, selfish, drags, kids, ...</td>\n",
       "      <td>[father, dysfunct, selfish, drag, kid, dysfunc...</td>\n",
       "      <td>[father, dysfunctional, selfish, drag, kid, dy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for lyft credit cannot use cause they d...</td>\n",
       "      <td>[thanks, for, lyft, credit, can, not, use, cau...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "      <td>[thank, lyft, credit, use, caus, offer, wheelc...</td>\n",
       "      <td>[thanks, lyft, credit, use, cause, offer, whee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>[bihday, majesti]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
       "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3    0.0                                bihday your majesty   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  when father is dysfunctional and is so selfish...   \n",
       "1  thanks for lyft credit cannot use cause they d...   \n",
       "2                                bihday your majesty   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  [when, father, is, dysfunctional, and, is, so,...   \n",
       "1  [thanks, for, lyft, credit, can, not, use, cau...   \n",
       "2                            [bihday, your, majesty]   \n",
       "\n",
       "                                tweet_token_filtered  \\\n",
       "0  [father, dysfunctional, selfish, drags, kids, ...   \n",
       "1  [thanks, lyft, credit, use, cause, offer, whee...   \n",
       "2                                  [bihday, majesty]   \n",
       "\n",
       "                                       tweet_stemmed  \\\n",
       "0  [father, dysfunct, selfish, drag, kid, dysfunc...   \n",
       "1  [thank, lyft, credit, use, caus, offer, wheelc...   \n",
       "2                                  [bihday, majesti]   \n",
       "\n",
       "                                    tweet_lemmatized  \n",
       "0  [father, dysfunctional, selfish, drag, kid, dy...  \n",
       "1  [thanks, lyft, credit, use, cause, offer, whee...  \n",
       "2                                  [bihday, majesty]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df .head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 49159/49159 [04:16<00:00, 191.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 17s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nlp = en_core_web_sm.load()\n",
    "combine_df['nlp'] = combine_df.clean_tweet.progress_apply(lambda x:  nlp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.max_length = combine_df['nlp'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for doc in combine_df['nlp'].tolist():\n",
    "    for e in doc.ents:\n",
    "        labels.append((e.label_, e.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_df = pd.DataFrame(labels, columns=['ner', 'word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE           11515\n",
       "PERSON          7999\n",
       "ORG             5563\n",
       "GPE             4572\n",
       "TIME            2033\n",
       "NORP            1451\n",
       "CARDINAL        1091\n",
       "ORDINAL          648\n",
       "FAC              302\n",
       "LOC              217\n",
       "EVENT            150\n",
       "PRODUCT           60\n",
       "LANGUAGE          42\n",
       "QUANTITY          34\n",
       "WORK_OF_ART       27\n",
       "LAW               22\n",
       "MONEY              8\n",
       "PERCENT            3\n",
       "Name: ner, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_df.ner.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hea                                                        119\n",
       "hu                                                          87\n",
       "blur sun                                                    55\n",
       "bihday                                                      47\n",
       "feminismiscancer feminismisterrorism feminismmuktbharat     40\n",
       "christina grimmie                                           38\n",
       "hillary                                                     37\n",
       "sikh temple                                                 28\n",
       "tgif ff                                                     26\n",
       "don                                                         24\n",
       "detoxdiet altwaystoheal                                     21\n",
       "clinton                                                     21\n",
       "ripchristina                                                20\n",
       "jo cox                                                      20\n",
       "carl paladino                                               19\n",
       "regrann                                                     17\n",
       "karen iqbal                                                 17\n",
       "donald trump                                                16\n",
       "anton yelchin                                               15\n",
       "moon                                                        15\n",
       "Name: word, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_df.loc[ner_df['ner'] == 'PERSON'].word.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bong bing           107\n",
       "app                  84\n",
       "gop                  77\n",
       "islam                58\n",
       "house                46\n",
       "social analytics     40\n",
       "nba                  39\n",
       "usa                  35\n",
       "amazon               32\n",
       "sta                  31\n",
       "sma                  30\n",
       "cnn                  28\n",
       "euro                 27\n",
       "fed                  25\n",
       "ios                  23\n",
       "eu                   22\n",
       "fbi                  21\n",
       "sun                  20\n",
       "bogota colombia      20\n",
       "congress             19\n",
       "Name: word, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_df.loc[ner_df['ner'] == 'ORG'].word.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2.\n",
    "\n",
    "Используя библиотеку nltk, вывести ТОП-20 популярных NER в combine_df датасете. Какой тип NER (ORG, GPE, PERSON и тд) оказался самым популярным? Для данного задания используем ограничение на количество символов во входном датасете (max_word_limit_spacy = 1000000), чтобы иметь возможность сравнить результаты работы Spacy и nltk. Обратите внимание, что nltk чувствителен к регистру.\n",
    "С помощью nltk выяснить: какие персоны и организации самые обсуждаемые в train и test датасетах? вывести ТОП-20 самых популярных. Действительно ли в топ вошли только персоны и организации или есть мусор?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_tweet = combine_df.tweet.to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_tweet_tokenize = nltk.word_tokenize(string_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_tweet_tags = nltk.pos_tag(string_tweet_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_tweet_chunk = nltk.ne_chunk (string_tweet_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('___', 'ORGANIZATION'),\n",
       " ('______________', 'ORGANIZATION'),\n",
       " ('_______________________', 'ORGANIZATION'),\n",
       " ('atÂ', 'ORGANIZATION'),\n",
       " ('babalargÃ¼nÃ¼', 'ORGANIZATION'),\n",
       " ('bearishÂ', 'ORGANIZATION'),\n",
       " ('braggingÂ', 'ORGANIZATION'),\n",
       " ('brÃ¼ssel', 'ORGANIZATION'),\n",
       " ('eatmorecrÃ', 'ORGANIZATION'),\n",
       " ('en-ger-land', 'GPE'),\n",
       " ('euro2016Â', 'ORGANIZATION'),\n",
       " ('euro2016Â Â', 'ORGANIZATION'),\n",
       " ('felicitÃ', 'ORGANIZATION'),\n",
       " ('firstÂ', 'ORGANIZATION'),\n",
       " ('foiinÃ', 'ORGANIZATION'),\n",
       " ('fridayÂ', 'ORGANIZATION'),\n",
       " ('fÃªte', 'ORGANIZATION'),\n",
       " ('gymð\\x9f\\x92ª', 'ORGANIZATION'),\n",
       " ('gÃ¼mbet', 'ORGANIZATION'),\n",
       " ('ilustraciÃ³n', 'ORGANIZATION'),\n",
       " ('inc.', 'ORGANIZATION'),\n",
       " ('l.a.', 'GPE'),\n",
       " ('marschfÃ¼rjesus', 'ORGANIZATION'),\n",
       " ('mr.', 'PERSON'),\n",
       " ('mr. paris', 'PERSON'),\n",
       " ('nycÂ', 'ORGANIZATION'),\n",
       " ('oilÂ', 'ORGANIZATION'),\n",
       " ('peace/sad', 'ORGANIZATION'),\n",
       " ('st.peter', 'ORGANIZATION'),\n",
       " ('sunflowerÂ', 'ORGANIZATION'),\n",
       " ('turÂ', 'ORGANIZATION'),\n",
       " ('u.s', 'GPE'),\n",
       " ('u.s.', 'GPE'),\n",
       " ('vysoÄ\\x8dina', 'ORGANIZATION'),\n",
       " ('whatÂ', 'ORGANIZATION'),\n",
       " ('zÃ¼rich', 'GPE'),\n",
       " ('ð\\x9f\\x93·', 'ORGANIZATION'),\n",
       " ('ó¾\\x93¯', 'ORGANIZATION')}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{(' '.join(c[0] for c in chunk), chunk.label() ) \\\n",
    " for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(string_tweet))) if hasattr(chunk, 'label') }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
