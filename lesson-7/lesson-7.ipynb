{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 30\n",
    "latent_dim = 256\n",
    "num_samples = 10000\n",
    "data_path = 'data/rus-eng/rus.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Собираем из текстов токены и делаем pne-hot вектора на каждый токен\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split('\\t')\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
    "    decoder_target_data[i, t:, target_token_index[' ']] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "125/125 [==============================] - 15s 123ms/step - loss: 1.1105 - accuracy: 0.7741 - val_loss: 0.9076 - val_accuracy: 0.7597\n",
      "Epoch 2/30\n",
      "125/125 [==============================] - 14s 115ms/step - loss: 0.7294 - accuracy: 0.8042 - val_loss: 0.7730 - val_accuracy: 0.7960\n",
      "Epoch 3/30\n",
      "125/125 [==============================] - 14s 116ms/step - loss: 0.6306 - accuracy: 0.8332 - val_loss: 0.6888 - val_accuracy: 0.8133\n",
      "Epoch 4/30\n",
      "125/125 [==============================] - 14s 115ms/step - loss: 0.5656 - accuracy: 0.8444 - val_loss: 0.6292 - val_accuracy: 0.8223\n",
      "Epoch 5/30\n",
      "125/125 [==============================] - 14s 115ms/step - loss: 0.5262 - accuracy: 0.8516 - val_loss: 0.5992 - val_accuracy: 0.8286\n",
      "Epoch 6/30\n",
      "125/125 [==============================] - 15s 118ms/step - loss: 0.5000 - accuracy: 0.8573 - val_loss: 0.5725 - val_accuracy: 0.8360\n",
      "Epoch 7/30\n",
      "125/125 [==============================] - 15s 124ms/step - loss: 0.4810 - accuracy: 0.8617 - val_loss: 0.5569 - val_accuracy: 0.8379\n",
      "Epoch 8/30\n",
      "125/125 [==============================] - 15s 118ms/step - loss: 0.5738 - accuracy: 0.8483 - val_loss: 0.6133 - val_accuracy: 0.8222\n",
      "Epoch 9/30\n",
      "125/125 [==============================] - 15s 116ms/step - loss: 0.5031 - accuracy: 0.8565 - val_loss: 0.5689 - val_accuracy: 0.8383\n",
      "Epoch 10/30\n",
      "125/125 [==============================] - 14s 116ms/step - loss: 0.4778 - accuracy: 0.8622 - val_loss: 0.5525 - val_accuracy: 0.8401\n",
      "Epoch 11/30\n",
      "125/125 [==============================] - 14s 116ms/step - loss: 0.4647 - accuracy: 0.8652 - val_loss: 0.5418 - val_accuracy: 0.8425\n",
      "Epoch 12/30\n",
      "125/125 [==============================] - 15s 118ms/step - loss: 0.4536 - accuracy: 0.8681 - val_loss: 0.5310 - val_accuracy: 0.8465\n",
      "Epoch 13/30\n",
      "125/125 [==============================] - 15s 117ms/step - loss: 0.4443 - accuracy: 0.8707 - val_loss: 0.5216 - val_accuracy: 0.8479\n",
      "Epoch 14/30\n",
      "125/125 [==============================] - 15s 120ms/step - loss: 0.4363 - accuracy: 0.8727 - val_loss: 0.5176 - val_accuracy: 0.8490\n",
      "Epoch 15/30\n",
      "125/125 [==============================] - 14s 116ms/step - loss: 0.4278 - accuracy: 0.8749 - val_loss: 0.5101 - val_accuracy: 0.8515\n",
      "Epoch 16/30\n",
      "125/125 [==============================] - 14s 115ms/step - loss: 0.4200 - accuracy: 0.8771 - val_loss: 0.5013 - val_accuracy: 0.8539\n",
      "Epoch 17/30\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.4117 - accuracy: 0.8792 - val_loss: 0.4933 - val_accuracy: 0.8559\n",
      "Epoch 18/30\n",
      "125/125 [==============================] - 14s 115ms/step - loss: 0.4040 - accuracy: 0.8812 - val_loss: 0.4883 - val_accuracy: 0.8576\n",
      "Epoch 19/30\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.3966 - accuracy: 0.8837 - val_loss: 0.4830 - val_accuracy: 0.8594\n",
      "Epoch 20/30\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.3884 - accuracy: 0.8863 - val_loss: 0.4771 - val_accuracy: 0.8612\n",
      "Epoch 21/30\n",
      "125/125 [==============================] - 14s 115ms/step - loss: 0.3812 - accuracy: 0.8882 - val_loss: 0.4733 - val_accuracy: 0.8633\n",
      "Epoch 22/30\n",
      "125/125 [==============================] - 14s 115ms/step - loss: 0.3746 - accuracy: 0.8903 - val_loss: 0.4680 - val_accuracy: 0.8651\n",
      "Epoch 23/30\n",
      "125/125 [==============================] - 14s 115ms/step - loss: 0.3672 - accuracy: 0.8927 - val_loss: 0.4646 - val_accuracy: 0.8644\n",
      "Epoch 24/30\n",
      "125/125 [==============================] - 14s 115ms/step - loss: 0.3593 - accuracy: 0.8948 - val_loss: 0.4585 - val_accuracy: 0.8666\n",
      "Epoch 25/30\n",
      "125/125 [==============================] - 14s 115ms/step - loss: 0.3526 - accuracy: 0.8969 - val_loss: 0.4565 - val_accuracy: 0.8688\n",
      "Epoch 26/30\n",
      "125/125 [==============================] - 14s 115ms/step - loss: 0.3454 - accuracy: 0.8988 - val_loss: 0.4515 - val_accuracy: 0.8704\n",
      "Epoch 27/30\n",
      "125/125 [==============================] - 15s 118ms/step - loss: 0.3387 - accuracy: 0.9008 - val_loss: 0.4469 - val_accuracy: 0.8705\n",
      "Epoch 28/30\n",
      "125/125 [==============================] - 15s 116ms/step - loss: 0.3318 - accuracy: 0.9030 - val_loss: 0.4422 - val_accuracy: 0.8727\n",
      "Epoch 29/30\n",
      "125/125 [==============================] - 14s 116ms/step - loss: 0.3258 - accuracy: 0.9046 - val_loss: 0.4437 - val_accuracy: 0.8728\n",
      "Epoch 30/30\n",
      "125/125 [==============================] - 14s 116ms/step - loss: 0.3183 - accuracy: 0.9068 - val_loss: 0.4378 - val_accuracy: 0.8749\n",
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Идите за меня.\n",
      "\n",
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Идите за меня.\n",
      "\n",
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Идите за меня.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Она может.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Она может.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Она может.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Она может.\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Она может.\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Поши мне не себя.\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Поши мне не себя.\n",
      "\n",
      "-\n",
      "Input sentence: Run.\n",
      "Decoded sentence: Поедите но мне!\n",
      "\n",
      "-\n",
      "Input sentence: Run.\n",
      "Decoded sentence: Поедите но мне!\n",
      "\n",
      "-\n",
      "Input sentence: Who?\n",
      "Decoded sentence: Кто так у бело?\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Вот на меня!\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Вот на меня!\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Вот на меня!\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Вот на меня!\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Вот на меня!\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Вот на меня!\n",
      "\n",
      "-\n",
      "Input sentence: Fire!\n",
      "Decoded sentence: Поднитесь!\n",
      "\n",
      "-\n",
      "Input sentence: Fire!\n",
      "Decoded sentence: Поднитесь!\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: Помите мне!\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: Помите мне!\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: Помите мне!\n",
      "\n",
      "-\n",
      "Input sentence: Jump!\n",
      "Decoded sentence: Простать е заном.\n",
      "\n",
      "-\n",
      "Input sentence: Jump!\n",
      "Decoded sentence: Простать е заном.\n",
      "\n",
      "-\n",
      "Input sentence: Jump.\n",
      "Decoded sentence: Простаньте его.\n",
      "\n",
      "-\n",
      "Input sentence: Jump.\n",
      "Decoded sentence: Простаньте его.\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Прекрати её.\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Прекрати её.\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Прекрати её.\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Подожди!\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Подожди!\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Подожди!\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Подожди!\n",
      "\n",
      "-\n",
      "Input sentence: Wait.\n",
      "Decoded sentence: Подожди Тома.\n",
      "\n",
      "-\n",
      "Input sentence: Wait.\n",
      "Decoded sentence: Подожди Тома.\n",
      "\n",
      "-\n",
      "Input sentence: Wait.\n",
      "Decoded sentence: Подожди Тома.\n",
      "\n",
      "-\n",
      "Input sentence: Do it.\n",
      "Decoded sentence: Не ого на?\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Иди за дема.\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Иди за дема.\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Привет, полен!\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Привет, полен!\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Привет, полен!\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Привет, полен!\n",
      "\n",
      "-\n",
      "Input sentence: Hurry!\n",
      "Decoded sentence: Вот на меня!\n",
      "\n",
      "-\n",
      "Input sentence: I ran.\n",
      "Decoded sentence: Я полодую.\n",
      "\n",
      "-\n",
      "Input sentence: I ran.\n",
      "Decoded sentence: Я полодую.\n",
      "\n",
      "-\n",
      "Input sentence: I ran.\n",
      "Decoded sentence: Я полодую.\n",
      "\n",
      "-\n",
      "Input sentence: I ran.\n",
      "Decoded sentence: Я полодую.\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Я полодил.\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Я полодил.\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Я полодил.\n",
      "\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence: Я полодуюсь.\n",
      "\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence: Я полодуюсь.\n",
      "\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence: Я полодуюсь.\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Я был поледна.\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Я был поледна.\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Я был поледна.\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Я был поледна.\n",
      "\n",
      "-\n",
      "Input sentence: Oh no!\n",
      "Decoded sentence: Что но мне на на мне?\n",
      "\n",
      "-\n",
      "Input sentence: Relax.\n",
      "Decoded sentence: Повидите за мней.\n",
      "\n",
      "-\n",
      "Input sentence: Relax.\n",
      "Decoded sentence: Повидите за мней.\n",
      "\n",
      "-\n",
      "Input sentence: Relax.\n",
      "Decoded sentence: Повидите за мней.\n",
      "\n",
      "-\n",
      "Input sentence: Shoot!\n",
      "Decoded sentence: Покажите мне!\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Подиньте за мнет.\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Подиньте за мнет.\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Подиньте за мнет.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Подиньте за мнет.\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Подиньте за мнет.\n",
      "\n",
      "-\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Подиньте за мнет.\n",
      "\n",
      "-\n",
      "Input sentence: Attack!\n",
      "Decoded sentence: Давай на вана.\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Будь серьёзно!\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Будь серьёзно!\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Будь серьёзно!\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Будь серьёзно!\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Будь серьёзно!\n",
      "\n",
      "-\n",
      "Input sentence: Eat it.\n",
      "Decoded sentence: Подожди Тома.\n",
      "\n",
      "-\n",
      "Input sentence: Eat up.\n",
      "Decoded sentence: Подожди Тома.\n",
      "\n",
      "-\n",
      "Input sentence: Freeze!\n",
      "Decoded sentence: Продолайте мне!\n",
      "\n",
      "-\n",
      "Input sentence: Freeze!\n",
      "Decoded sentence: Продолайте мне!\n",
      "\n",
      "-\n",
      "Input sentence: Freeze!\n",
      "Decoded sentence: Продолайте мне!\n",
      "\n",
      "-\n",
      "Input sentence: Freeze!\n",
      "Decoded sentence: Продолайте мне!\n",
      "\n",
      "-\n",
      "Input sentence: Get up.\n",
      "Decoded sentence: Привалийся.\n",
      "\n",
      "-\n",
      "Input sentence: Get up.\n",
      "Decoded sentence: Привалийся.\n",
      "\n",
      "-\n",
      "Input sentence: Get up.\n",
      "Decoded sentence: Привалийся.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Иди за демаю.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Иди за демаю.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Иди за демаю.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Иди за демаю.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Иди за демаю.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Иди за демаю.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Иди за демаю.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Иди за демаю.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Иди за демаю.\n",
      "\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence: Подните это.\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Постаньте это.\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Постаньте это.\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Постаньте это.\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Постаньте это.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)\n",
    "\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "for seq_index in range(100):\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поднимемся на уровень слов, чтобы можно было что-то более адекватное посчитать за адекватное время"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tensorflow as tf\n",
    "data_path = 'data/rus-eng/rus.txt'\n",
    "num_samples = 10000\n",
    "\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    \n",
    "    \"\"\"Предобработка пунктуации последовательности\"\"\"\n",
    "        \n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    w = re.sub(r\"[^a-zA-Zа-яА-Я]+\", \" \", w)\n",
    "    w = w.strip()\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w\n",
    "\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split('\\t')\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(preprocess_sentence(input_text))\n",
    "    target_texts.append(preprocess_sentence(target_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor, inp_lang_tokenizer = tokenize(input_texts)\n",
    "target_tensor, targ_lang_tokenizer = tokenize(target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "\n",
    "vocab_inp_size = len(inp_lang_tokenizer.word_index)+1\n",
    "vocab_tar_size = len(targ_lang_tokenizer.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.lstm(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))\n",
    "\n",
    "    \n",
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights\n",
    "    \n",
    "    \n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        output, state = self.lstm(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        x = self.fc(output)\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        dec_hidden = enc_hidden\n",
    "        dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "    \n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 1.7895\n",
      "Epoch 2 Loss 1.4252\n",
      "Epoch 3 Loss 1.2377\n",
      "Epoch 4 Loss 1.0622\n",
      "Epoch 5 Loss 0.8912\n",
      "Epoch 6 Loss 0.7264\n",
      "Epoch 7 Loss 0.5857\n",
      "Epoch 8 Loss 0.4738\n",
      "Epoch 9 Loss 0.3876\n",
      "Epoch 10 Loss 0.3301\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "    \n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые украденные функции для оценки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
    "\n",
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    inputs = [inp_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    result = ''\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += targ_lang_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if targ_lang_tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "    return result, sentence, attention_plot\n",
    "\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    fontdict = {'fontsize': 14}\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    plt.show()\n",
    "    \n",
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "Input: <start> good morning <end>\n",
      "Predicted translation: спокойной ночи <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\NLP\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['char', 'f']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n",
      "D:\\anaconda3\\envs\\NLP\\lib\\site-packages\\ipykernel_launcher.py:38: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "D:\\anaconda3\\envs\\NLP\\lib\\site-packages\\ipykernel_launcher.py:39: UserWarning: FixedFormatter should only be used together with FixedLocator\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ticker' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-c62fe7b3b252>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pylab'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'good morning'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-61331b77bd12>\u001b[0m in \u001b[0;36mtranslate\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Predicted translation: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mattention_plot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattention_plot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mplot_attention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_plot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-61331b77bd12>\u001b[0m in \u001b[0;36mplot_attention\u001b[1;34m(attention, sentence, predicted_sentence)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xticklabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontdict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfontdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrotation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m90\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_yticklabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpredicted_sentence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontdict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfontdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_major_locator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultipleLocator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_major_locator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultipleLocator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ticker' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "translate(u'good morning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "  q, k, v must have matching leading dimensions.\n",
    "  k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "  The mask has different shapes depending on its type(padding or look ahead) \n",
    "  but it must be broadcastable for addition.\n",
    "  \n",
    "  Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "    \n",
    "  Returns:\n",
    "    output, attention_weights\n",
    "    \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "  \n",
    "  # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "  # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "  # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights\n",
    "    \n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2\n",
    "    \n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    \n",
    "    def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(\n",
    "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2\n",
    "    \n",
    "    \n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                                self.d_model)\n",
    "\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # adding embedding and position encoding.\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                                 look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                               input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                               target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "    def call(self, inp, tar, training, enc_padding_mask, \n",
    "           look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "            tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = len(inp_lang_tokenizer.index_word) + 2\n",
    "target_vocab_size = len(targ_lang_tokenizer.index_word) + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "  \n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "  \n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')\n",
    "\n",
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "  \n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "  \n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int32),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "  \n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "  \n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(inp, tar_inp, \n",
    "                                 True, \n",
    "                                 enc_padding_mask, \n",
    "                                 combined_mask, \n",
    "                                 dec_padding_mask)\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "  \n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 8.4978 Accuracy 0.0000\n",
      "Epoch 1 Batch 50 Loss 8.3017 Accuracy 0.0351\n",
      "Epoch 1 Batch 100 Loss 8.0487 Accuracy 0.0727\n",
      "Epoch 1 Loss 7.9582 Accuracy 0.0801\n",
      "Epoch 2 Batch 0 Loss 7.4909 Accuracy 0.1111\n",
      "Epoch 2 Batch 50 Loss 7.3659 Accuracy 0.1111\n",
      "Epoch 2 Batch 100 Loss 7.1963 Accuracy 0.1111\n",
      "Epoch 2 Loss 7.1038 Accuracy 0.1116\n",
      "Epoch 3 Batch 0 Loss 6.6238 Accuracy 0.1285\n",
      "Epoch 3 Batch 50 Loss 6.3424 Accuracy 0.1366\n",
      "Epoch 3 Batch 100 Loss 6.1126 Accuracy 0.1386\n",
      "Epoch 3 Loss 6.0116 Accuracy 0.1393\n",
      "Epoch 4 Batch 0 Loss 5.4580 Accuracy 0.1389\n",
      "Epoch 4 Batch 50 Loss 5.2589 Accuracy 0.1405\n",
      "Epoch 4 Batch 100 Loss 5.0958 Accuracy 0.1423\n",
      "Epoch 4 Loss 5.0384 Accuracy 0.1443\n",
      "Epoch 5 Batch 0 Loss 4.6636 Accuracy 0.1719\n",
      "Epoch 5 Batch 50 Loss 4.5765 Accuracy 0.1641\n",
      "Epoch 5 Batch 100 Loss 4.4836 Accuracy 0.1678\n",
      "Epoch 5 Loss 4.4363 Accuracy 0.1688\n",
      "Epoch 6 Batch 0 Loss 4.1594 Accuracy 0.1701\n",
      "Epoch 6 Batch 50 Loss 4.1183 Accuracy 0.1743\n",
      "Epoch 6 Batch 100 Loss 4.0615 Accuracy 0.1752\n",
      "Epoch 6 Loss 4.0349 Accuracy 0.1762\n",
      "Epoch 7 Batch 0 Loss 3.8028 Accuracy 0.1823\n",
      "Epoch 7 Batch 50 Loss 3.8111 Accuracy 0.1799\n",
      "Epoch 7 Batch 100 Loss 3.7596 Accuracy 0.1816\n",
      "Epoch 7 Loss 3.7344 Accuracy 0.1827\n",
      "Epoch 8 Batch 0 Loss 3.5718 Accuracy 0.1858\n",
      "Epoch 8 Batch 50 Loss 3.5273 Accuracy 0.1886\n",
      "Epoch 8 Batch 100 Loss 3.5162 Accuracy 0.1877\n",
      "Epoch 8 Loss 3.5065 Accuracy 0.1883\n",
      "Epoch 9 Batch 0 Loss 3.1907 Accuracy 0.2083\n",
      "Epoch 9 Batch 50 Loss 3.3267 Accuracy 0.1928\n",
      "Epoch 9 Batch 100 Loss 3.3032 Accuracy 0.1931\n",
      "Epoch 9 Loss 3.2882 Accuracy 0.1940\n",
      "Epoch 10 Batch 0 Loss 3.1687 Accuracy 0.1962\n",
      "Epoch 10 Batch 50 Loss 3.1100 Accuracy 0.1981\n",
      "Epoch 10 Batch 100 Loss 3.1046 Accuracy 0.1995\n",
      "Epoch 10 Loss 3.1025 Accuracy 0.1994\n",
      "Epoch 11 Batch 0 Loss 2.9425 Accuracy 0.2083\n",
      "Epoch 11 Batch 50 Loss 2.9180 Accuracy 0.2038\n",
      "Epoch 11 Batch 100 Loss 2.9197 Accuracy 0.2049\n",
      "Epoch 11 Loss 2.9217 Accuracy 0.2040\n",
      "Epoch 12 Batch 0 Loss 2.8293 Accuracy 0.2205\n",
      "Epoch 12 Batch 50 Loss 2.7101 Accuracy 0.2110\n",
      "Epoch 12 Batch 100 Loss 2.7393 Accuracy 0.2102\n",
      "Epoch 12 Loss 2.7371 Accuracy 0.2103\n",
      "Epoch 13 Batch 0 Loss 2.6254 Accuracy 0.2066\n",
      "Epoch 13 Batch 50 Loss 2.5528 Accuracy 0.2166\n",
      "Epoch 13 Batch 100 Loss 2.5634 Accuracy 0.2162\n",
      "Epoch 13 Loss 2.5717 Accuracy 0.2163\n",
      "Epoch 14 Batch 0 Loss 2.2240 Accuracy 0.2361\n",
      "Epoch 14 Batch 50 Loss 2.3710 Accuracy 0.2235\n",
      "Epoch 14 Batch 100 Loss 2.3857 Accuracy 0.2230\n",
      "Epoch 14 Loss 2.4027 Accuracy 0.2219\n",
      "Epoch 15 Batch 0 Loss 2.2294 Accuracy 0.2066\n",
      "Epoch 15 Batch 50 Loss 2.2155 Accuracy 0.2280\n",
      "Epoch 15 Batch 100 Loss 2.2228 Accuracy 0.2274\n",
      "Epoch 15 Loss 2.2280 Accuracy 0.2274\n",
      "Epoch 16 Batch 0 Loss 2.2856 Accuracy 0.2309\n",
      "Epoch 16 Batch 50 Loss 2.0330 Accuracy 0.2363\n",
      "Epoch 16 Batch 100 Loss 2.0610 Accuracy 0.2350\n",
      "Epoch 16 Loss 2.0729 Accuracy 0.2347\n",
      "Epoch 17 Batch 0 Loss 1.9600 Accuracy 0.2517\n",
      "Epoch 17 Batch 50 Loss 1.9113 Accuracy 0.2395\n",
      "Epoch 17 Batch 100 Loss 1.9129 Accuracy 0.2403\n",
      "Epoch 17 Loss 1.9180 Accuracy 0.2401\n",
      "Epoch 18 Batch 0 Loss 1.9768 Accuracy 0.2274\n",
      "Epoch 18 Batch 50 Loss 1.7489 Accuracy 0.2477\n",
      "Epoch 18 Batch 100 Loss 1.7814 Accuracy 0.2467\n",
      "Epoch 18 Loss 1.7846 Accuracy 0.2466\n",
      "Epoch 19 Batch 0 Loss 1.6751 Accuracy 0.2309\n",
      "Epoch 19 Batch 50 Loss 1.6003 Accuracy 0.2554\n",
      "Epoch 19 Batch 100 Loss 1.6160 Accuracy 0.2534\n",
      "Epoch 19 Loss 1.6358 Accuracy 0.2527\n",
      "Epoch 20 Batch 0 Loss 1.4787 Accuracy 0.2500\n",
      "Epoch 20 Batch 50 Loss 1.4638 Accuracy 0.2622\n",
      "Epoch 20 Batch 100 Loss 1.4994 Accuracy 0.2592\n",
      "Epoch 20 Loss 1.5163 Accuracy 0.2576\n",
      "Epoch 21 Batch 0 Loss 1.3983 Accuracy 0.2552\n",
      "Epoch 21 Batch 50 Loss 1.3244 Accuracy 0.2702\n",
      "Epoch 21 Batch 100 Loss 1.3718 Accuracy 0.2668\n",
      "Epoch 21 Loss 1.3956 Accuracy 0.2642\n",
      "Epoch 22 Batch 0 Loss 1.3001 Accuracy 0.2622\n",
      "Epoch 22 Batch 50 Loss 1.2165 Accuracy 0.2737\n",
      "Epoch 22 Batch 100 Loss 1.2686 Accuracy 0.2705\n",
      "Epoch 22 Loss 1.2877 Accuracy 0.2694\n",
      "Epoch 23 Batch 0 Loss 1.0770 Accuracy 0.3056\n",
      "Epoch 23 Batch 50 Loss 1.1172 Accuracy 0.2841\n",
      "Epoch 23 Batch 100 Loss 1.1742 Accuracy 0.2758\n",
      "Epoch 23 Loss 1.1974 Accuracy 0.2737\n",
      "Epoch 24 Batch 0 Loss 0.9489 Accuracy 0.2812\n",
      "Epoch 24 Batch 50 Loss 1.0482 Accuracy 0.2844\n",
      "Epoch 24 Batch 100 Loss 1.0920 Accuracy 0.2793\n",
      "Epoch 24 Loss 1.1150 Accuracy 0.2770\n",
      "Epoch 25 Batch 0 Loss 0.9026 Accuracy 0.3090\n",
      "Epoch 25 Batch 50 Loss 0.9797 Accuracy 0.2880\n",
      "Epoch 25 Batch 100 Loss 1.0292 Accuracy 0.2832\n",
      "Epoch 25 Loss 1.0450 Accuracy 0.2820\n",
      "Epoch 26 Batch 0 Loss 0.7819 Accuracy 0.3177\n",
      "Epoch 26 Batch 50 Loss 0.9139 Accuracy 0.2916\n",
      "Epoch 26 Batch 100 Loss 0.9708 Accuracy 0.2859\n",
      "Epoch 26 Loss 0.9982 Accuracy 0.2835\n",
      "Epoch 27 Batch 0 Loss 0.7871 Accuracy 0.2986\n",
      "Epoch 27 Batch 50 Loss 0.8507 Accuracy 0.2954\n",
      "Epoch 27 Batch 100 Loss 0.9143 Accuracy 0.2890\n",
      "Epoch 27 Loss 0.9467 Accuracy 0.2867\n",
      "Epoch 28 Batch 0 Loss 0.8363 Accuracy 0.2934\n",
      "Epoch 28 Batch 50 Loss 0.8041 Accuracy 0.2982\n",
      "Epoch 28 Batch 100 Loss 0.8809 Accuracy 0.2919\n",
      "Epoch 28 Loss 0.9113 Accuracy 0.2894\n",
      "Epoch 29 Batch 0 Loss 0.7915 Accuracy 0.2882\n",
      "Epoch 29 Batch 50 Loss 0.7658 Accuracy 0.3011\n",
      "Epoch 29 Batch 100 Loss 0.8423 Accuracy 0.2934\n",
      "Epoch 29 Loss 0.8768 Accuracy 0.2909\n",
      "Epoch 30 Batch 0 Loss 0.7632 Accuracy 0.3177\n",
      "Epoch 30 Batch 50 Loss 0.7598 Accuracy 0.3037\n",
      "Epoch 30 Batch 100 Loss 0.8312 Accuracy 0.2956\n",
      "Epoch 30 Loss 0.8607 Accuracy 0.2923\n",
      "Epoch 31 Batch 0 Loss 0.5794 Accuracy 0.3194\n",
      "Epoch 31 Batch 50 Loss 0.7410 Accuracy 0.3033\n",
      "Epoch 31 Batch 100 Loss 0.8214 Accuracy 0.2958\n",
      "Epoch 31 Loss 0.8534 Accuracy 0.2925\n",
      "Epoch 32 Batch 0 Loss 0.7342 Accuracy 0.2951\n",
      "Epoch 32 Batch 50 Loss 0.7237 Accuracy 0.3061\n",
      "Epoch 32 Batch 100 Loss 0.8115 Accuracy 0.2976\n",
      "Epoch 32 Loss 0.8382 Accuracy 0.2949\n",
      "Epoch 33 Batch 0 Loss 0.6752 Accuracy 0.3125\n",
      "Epoch 33 Batch 50 Loss 0.7289 Accuracy 0.3039\n",
      "Epoch 33 Batch 100 Loss 0.8026 Accuracy 0.2982\n",
      "Epoch 33 Loss 0.8249 Accuracy 0.2952\n",
      "Epoch 34 Batch 0 Loss 0.6858 Accuracy 0.3125\n",
      "Epoch 34 Batch 50 Loss 0.6850 Accuracy 0.3077\n",
      "Epoch 34 Batch 100 Loss 0.7573 Accuracy 0.3014\n",
      "Epoch 34 Loss 0.7917 Accuracy 0.2982\n",
      "Epoch 35 Batch 0 Loss 0.5262 Accuracy 0.3177\n",
      "Epoch 35 Batch 50 Loss 0.6771 Accuracy 0.3062\n",
      "Epoch 35 Batch 100 Loss 0.7520 Accuracy 0.3011\n",
      "Epoch 35 Loss 0.7786 Accuracy 0.2988\n",
      "Epoch 36 Batch 0 Loss 0.5390 Accuracy 0.3351\n",
      "Epoch 36 Batch 50 Loss 0.6601 Accuracy 0.3109\n",
      "Epoch 36 Batch 100 Loss 0.7286 Accuracy 0.3028\n",
      "Epoch 36 Loss 0.7550 Accuracy 0.3009\n",
      "Epoch 37 Batch 0 Loss 0.6119 Accuracy 0.3038\n",
      "Epoch 37 Batch 50 Loss 0.6388 Accuracy 0.3119\n",
      "Epoch 37 Batch 100 Loss 0.7144 Accuracy 0.3034\n",
      "Epoch 37 Loss 0.7330 Accuracy 0.3028\n",
      "Epoch 38 Batch 0 Loss 0.6303 Accuracy 0.3316\n",
      "Epoch 38 Batch 50 Loss 0.6303 Accuracy 0.3115\n",
      "Epoch 38 Batch 100 Loss 0.6831 Accuracy 0.3072\n",
      "Epoch 38 Loss 0.7115 Accuracy 0.3042\n",
      "Epoch 39 Batch 0 Loss 0.5748 Accuracy 0.3125\n",
      "Epoch 39 Batch 50 Loss 0.6168 Accuracy 0.3132\n",
      "Epoch 39 Batch 100 Loss 0.6706 Accuracy 0.3081\n",
      "Epoch 39 Loss 0.7029 Accuracy 0.3056\n",
      "Epoch 40 Batch 0 Loss 0.5706 Accuracy 0.3299\n",
      "Epoch 40 Batch 50 Loss 0.6094 Accuracy 0.3143\n",
      "Epoch 40 Batch 100 Loss 0.6693 Accuracy 0.3078\n",
      "Epoch 40 Loss 0.6923 Accuracy 0.3053\n",
      "Epoch 41 Batch 0 Loss 0.5025 Accuracy 0.3125\n",
      "Epoch 41 Batch 50 Loss 0.6080 Accuracy 0.3122\n",
      "Epoch 41 Batch 100 Loss 0.6599 Accuracy 0.3087\n",
      "Epoch 41 Loss 0.6823 Accuracy 0.3066\n",
      "Epoch 42 Batch 0 Loss 0.6656 Accuracy 0.3212\n",
      "Epoch 42 Batch 50 Loss 0.5723 Accuracy 0.3163\n",
      "Epoch 42 Batch 100 Loss 0.6422 Accuracy 0.3107\n",
      "Epoch 42 Loss 0.6670 Accuracy 0.3082\n",
      "Epoch 43 Batch 0 Loss 0.4288 Accuracy 0.3403\n",
      "Epoch 43 Batch 50 Loss 0.5565 Accuracy 0.3188\n",
      "Epoch 43 Batch 100 Loss 0.6270 Accuracy 0.3118\n",
      "Epoch 43 Loss 0.6487 Accuracy 0.3099\n",
      "Epoch 44 Batch 0 Loss 0.5641 Accuracy 0.3090\n",
      "Epoch 44 Batch 50 Loss 0.5686 Accuracy 0.3186\n",
      "Epoch 44 Batch 100 Loss 0.6228 Accuracy 0.3123\n",
      "Epoch 44 Loss 0.6481 Accuracy 0.3101\n",
      "Epoch 45 Batch 0 Loss 0.6202 Accuracy 0.3003\n",
      "Epoch 45 Batch 50 Loss 0.5670 Accuracy 0.3164\n",
      "Epoch 45 Batch 100 Loss 0.6193 Accuracy 0.3114\n",
      "Epoch 45 Loss 0.6377 Accuracy 0.3104\n",
      "Epoch 46 Batch 0 Loss 0.4507 Accuracy 0.3299\n",
      "Epoch 46 Batch 50 Loss 0.5382 Accuracy 0.3205\n",
      "Epoch 46 Batch 100 Loss 0.5924 Accuracy 0.3150\n",
      "Epoch 46 Loss 0.6167 Accuracy 0.3130\n",
      "Epoch 47 Batch 0 Loss 0.6311 Accuracy 0.3090\n",
      "Epoch 47 Batch 50 Loss 0.5440 Accuracy 0.3184\n",
      "Epoch 47 Batch 100 Loss 0.5884 Accuracy 0.3146\n",
      "Epoch 47 Loss 0.6155 Accuracy 0.3129\n",
      "Epoch 48 Batch 0 Loss 0.5336 Accuracy 0.3368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Batch 50 Loss 0.5391 Accuracy 0.3204\n",
      "Epoch 48 Batch 100 Loss 0.5820 Accuracy 0.3166\n",
      "Epoch 48 Loss 0.6057 Accuracy 0.3137\n",
      "Epoch 49 Batch 0 Loss 0.4804 Accuracy 0.3247\n",
      "Epoch 49 Batch 50 Loss 0.5166 Accuracy 0.3201\n",
      "Epoch 49 Batch 100 Loss 0.5781 Accuracy 0.3164\n",
      "Epoch 49 Loss 0.5986 Accuracy 0.3143\n",
      "Epoch 50 Batch 0 Loss 0.4087 Accuracy 0.3333\n",
      "Epoch 50 Batch 50 Loss 0.5157 Accuracy 0.3209\n",
      "Epoch 50 Batch 100 Loss 0.5707 Accuracy 0.3166\n",
      "Epoch 50 Loss 0.5920 Accuracy 0.3145\n",
      "Epoch 51 Batch 0 Loss 0.4769 Accuracy 0.3299\n",
      "Epoch 51 Batch 50 Loss 0.4970 Accuracy 0.3232\n",
      "Epoch 51 Batch 100 Loss 0.5538 Accuracy 0.3181\n",
      "Epoch 51 Loss 0.5753 Accuracy 0.3161\n",
      "Epoch 52 Batch 0 Loss 0.3472 Accuracy 0.3542\n",
      "Epoch 52 Batch 50 Loss 0.5026 Accuracy 0.3258\n",
      "Epoch 52 Batch 100 Loss 0.5555 Accuracy 0.3183\n",
      "Epoch 52 Loss 0.5823 Accuracy 0.3159\n",
      "Epoch 53 Batch 0 Loss 0.4701 Accuracy 0.3299\n",
      "Epoch 53 Batch 50 Loss 0.5051 Accuracy 0.3223\n",
      "Epoch 53 Batch 100 Loss 0.5558 Accuracy 0.3176\n",
      "Epoch 53 Loss 0.5750 Accuracy 0.3161\n",
      "Epoch 54 Batch 0 Loss 0.3551 Accuracy 0.3351\n",
      "Epoch 54 Batch 50 Loss 0.4922 Accuracy 0.3214\n",
      "Epoch 54 Batch 100 Loss 0.5513 Accuracy 0.3163\n",
      "Epoch 54 Loss 0.5716 Accuracy 0.3150\n",
      "Epoch 55 Batch 0 Loss 0.5355 Accuracy 0.3247\n",
      "Epoch 55 Batch 50 Loss 0.4895 Accuracy 0.3228\n",
      "Epoch 55 Batch 100 Loss 0.5388 Accuracy 0.3182\n",
      "Epoch 55 Loss 0.5592 Accuracy 0.3167\n",
      "Epoch 56 Batch 0 Loss 0.3912 Accuracy 0.3490\n",
      "Epoch 56 Batch 50 Loss 0.4808 Accuracy 0.3260\n",
      "Epoch 56 Batch 100 Loss 0.5418 Accuracy 0.3189\n",
      "Epoch 56 Loss 0.5642 Accuracy 0.3166\n",
      "Epoch 57 Batch 0 Loss 0.4433 Accuracy 0.3281\n",
      "Epoch 57 Batch 50 Loss 0.4845 Accuracy 0.3225\n",
      "Epoch 57 Batch 100 Loss 0.5342 Accuracy 0.3189\n",
      "Epoch 57 Loss 0.5475 Accuracy 0.3175\n",
      "Epoch 58 Batch 0 Loss 0.3854 Accuracy 0.3403\n",
      "Epoch 58 Batch 50 Loss 0.4638 Accuracy 0.3245\n",
      "Epoch 58 Batch 100 Loss 0.5200 Accuracy 0.3213\n",
      "Epoch 58 Loss 0.5435 Accuracy 0.3191\n",
      "Epoch 59 Batch 0 Loss 0.5355 Accuracy 0.3021\n",
      "Epoch 59 Batch 50 Loss 0.4757 Accuracy 0.3233\n",
      "Epoch 59 Batch 100 Loss 0.5326 Accuracy 0.3183\n",
      "Epoch 59 Loss 0.5534 Accuracy 0.3161\n",
      "Epoch 60 Batch 0 Loss 0.3692 Accuracy 0.3403\n",
      "Epoch 60 Batch 50 Loss 0.4587 Accuracy 0.3270\n",
      "Epoch 60 Batch 100 Loss 0.5162 Accuracy 0.3212\n",
      "Epoch 60 Loss 0.5455 Accuracy 0.3183\n",
      "Epoch 61 Batch 0 Loss 0.3992 Accuracy 0.3299\n",
      "Epoch 61 Batch 50 Loss 0.4660 Accuracy 0.3252\n",
      "Epoch 61 Batch 100 Loss 0.5117 Accuracy 0.3204\n",
      "Epoch 61 Loss 0.5368 Accuracy 0.3182\n",
      "Epoch 62 Batch 0 Loss 0.3885 Accuracy 0.3247\n",
      "Epoch 62 Batch 50 Loss 0.4577 Accuracy 0.3248\n",
      "Epoch 62 Batch 100 Loss 0.5052 Accuracy 0.3210\n",
      "Epoch 62 Loss 0.5310 Accuracy 0.3187\n",
      "Epoch 63 Batch 0 Loss 0.3787 Accuracy 0.3507\n",
      "Epoch 63 Batch 50 Loss 0.4586 Accuracy 0.3253\n",
      "Epoch 63 Batch 100 Loss 0.5045 Accuracy 0.3215\n",
      "Epoch 63 Loss 0.5276 Accuracy 0.3196\n",
      "Epoch 64 Batch 0 Loss 0.4330 Accuracy 0.3420\n",
      "Epoch 64 Batch 50 Loss 0.4520 Accuracy 0.3270\n",
      "Epoch 64 Batch 100 Loss 0.5041 Accuracy 0.3211\n",
      "Epoch 64 Loss 0.5237 Accuracy 0.3193\n",
      "Epoch 65 Batch 0 Loss 0.3484 Accuracy 0.3438\n",
      "Epoch 65 Batch 50 Loss 0.4514 Accuracy 0.3267\n",
      "Epoch 65 Batch 100 Loss 0.4980 Accuracy 0.3222\n",
      "Epoch 65 Loss 0.5218 Accuracy 0.3193\n",
      "Epoch 66 Batch 0 Loss 0.3780 Accuracy 0.3490\n",
      "Epoch 66 Batch 50 Loss 0.4342 Accuracy 0.3281\n",
      "Epoch 66 Batch 100 Loss 0.4952 Accuracy 0.3207\n",
      "Epoch 66 Loss 0.5131 Accuracy 0.3193\n",
      "Epoch 67 Batch 0 Loss 0.4136 Accuracy 0.3333\n",
      "Epoch 67 Batch 50 Loss 0.4465 Accuracy 0.3252\n",
      "Epoch 67 Batch 100 Loss 0.4891 Accuracy 0.3212\n",
      "Epoch 67 Loss 0.5101 Accuracy 0.3193\n",
      "Epoch 68 Batch 0 Loss 0.3856 Accuracy 0.3403\n",
      "Epoch 68 Batch 50 Loss 0.4486 Accuracy 0.3260\n",
      "Epoch 68 Batch 100 Loss 0.4916 Accuracy 0.3221\n",
      "Epoch 68 Loss 0.5112 Accuracy 0.3207\n",
      "Epoch 69 Batch 0 Loss 0.3663 Accuracy 0.3125\n",
      "Epoch 69 Batch 50 Loss 0.4389 Accuracy 0.3254\n",
      "Epoch 69 Batch 100 Loss 0.4898 Accuracy 0.3208\n",
      "Epoch 69 Loss 0.5092 Accuracy 0.3202\n",
      "Epoch 70 Batch 0 Loss 0.3760 Accuracy 0.3403\n",
      "Epoch 70 Batch 50 Loss 0.4360 Accuracy 0.3282\n",
      "Epoch 70 Batch 100 Loss 0.4855 Accuracy 0.3226\n",
      "Epoch 70 Loss 0.5088 Accuracy 0.3199\n",
      "Epoch 71 Batch 0 Loss 0.3127 Accuracy 0.3403\n",
      "Epoch 71 Batch 50 Loss 0.4393 Accuracy 0.3284\n",
      "Epoch 71 Batch 100 Loss 0.4768 Accuracy 0.3236\n",
      "Epoch 71 Loss 0.4998 Accuracy 0.3210\n",
      "Epoch 72 Batch 0 Loss 0.3580 Accuracy 0.3368\n",
      "Epoch 72 Batch 50 Loss 0.4377 Accuracy 0.3254\n",
      "Epoch 72 Batch 100 Loss 0.4785 Accuracy 0.3228\n",
      "Epoch 72 Loss 0.4970 Accuracy 0.3209\n",
      "Epoch 73 Batch 0 Loss 0.3731 Accuracy 0.3333\n",
      "Epoch 73 Batch 50 Loss 0.4254 Accuracy 0.3291\n",
      "Epoch 73 Batch 100 Loss 0.4767 Accuracy 0.3227\n",
      "Epoch 73 Loss 0.4948 Accuracy 0.3210\n",
      "Epoch 74 Batch 0 Loss 0.3724 Accuracy 0.3281\n",
      "Epoch 74 Batch 50 Loss 0.4185 Accuracy 0.3278\n",
      "Epoch 74 Batch 100 Loss 0.4757 Accuracy 0.3227\n",
      "Epoch 74 Loss 0.4933 Accuracy 0.3212\n",
      "Epoch 75 Batch 0 Loss 0.3877 Accuracy 0.3281\n",
      "Epoch 75 Batch 50 Loss 0.4366 Accuracy 0.3269\n",
      "Epoch 75 Batch 100 Loss 0.4692 Accuracy 0.3231\n",
      "Epoch 75 Loss 0.4852 Accuracy 0.3213\n",
      "Epoch 76 Batch 0 Loss 0.3423 Accuracy 0.3351\n",
      "Epoch 76 Batch 50 Loss 0.4246 Accuracy 0.3291\n",
      "Epoch 76 Batch 100 Loss 0.4703 Accuracy 0.3223\n",
      "Epoch 76 Loss 0.4903 Accuracy 0.3213\n",
      "Epoch 77 Batch 0 Loss 0.4234 Accuracy 0.3229\n",
      "Epoch 77 Batch 50 Loss 0.4299 Accuracy 0.3275\n",
      "Epoch 77 Batch 100 Loss 0.4708 Accuracy 0.3229\n",
      "Epoch 77 Loss 0.4898 Accuracy 0.3209\n",
      "Epoch 78 Batch 0 Loss 0.4399 Accuracy 0.3368\n",
      "Epoch 78 Batch 50 Loss 0.4181 Accuracy 0.3277\n",
      "Epoch 78 Batch 100 Loss 0.4662 Accuracy 0.3228\n",
      "Epoch 78 Loss 0.4808 Accuracy 0.3214\n",
      "Epoch 79 Batch 0 Loss 0.3297 Accuracy 0.3316\n",
      "Epoch 79 Batch 50 Loss 0.4129 Accuracy 0.3311\n",
      "Epoch 79 Batch 100 Loss 0.4594 Accuracy 0.3244\n",
      "Epoch 79 Loss 0.4780 Accuracy 0.3220\n",
      "Epoch 80 Batch 0 Loss 0.3413 Accuracy 0.3212\n",
      "Epoch 80 Batch 50 Loss 0.4143 Accuracy 0.3251\n",
      "Epoch 80 Batch 100 Loss 0.4505 Accuracy 0.3248\n",
      "Epoch 80 Loss 0.4726 Accuracy 0.3223\n",
      "Epoch 81 Batch 0 Loss 0.3280 Accuracy 0.3455\n",
      "Epoch 81 Batch 50 Loss 0.4123 Accuracy 0.3299\n",
      "Epoch 81 Batch 100 Loss 0.4496 Accuracy 0.3242\n",
      "Epoch 81 Loss 0.4720 Accuracy 0.3221\n",
      "Epoch 82 Batch 0 Loss 0.3766 Accuracy 0.3351\n",
      "Epoch 82 Batch 50 Loss 0.4145 Accuracy 0.3292\n",
      "Epoch 82 Batch 100 Loss 0.4628 Accuracy 0.3237\n",
      "Epoch 82 Loss 0.4798 Accuracy 0.3215\n",
      "Epoch 83 Batch 0 Loss 0.4048 Accuracy 0.3351\n",
      "Epoch 83 Batch 50 Loss 0.4006 Accuracy 0.3319\n",
      "Epoch 83 Batch 100 Loss 0.4530 Accuracy 0.3248\n",
      "Epoch 83 Loss 0.4697 Accuracy 0.3227\n",
      "Epoch 84 Batch 0 Loss 0.3377 Accuracy 0.3438\n",
      "Epoch 84 Batch 50 Loss 0.4067 Accuracy 0.3288\n",
      "Epoch 84 Batch 100 Loss 0.4431 Accuracy 0.3252\n",
      "Epoch 84 Loss 0.4636 Accuracy 0.3228\n",
      "Epoch 85 Batch 0 Loss 0.3086 Accuracy 0.3490\n",
      "Epoch 85 Batch 50 Loss 0.4028 Accuracy 0.3311\n",
      "Epoch 85 Batch 100 Loss 0.4476 Accuracy 0.3249\n",
      "Epoch 85 Loss 0.4647 Accuracy 0.3222\n",
      "Epoch 86 Batch 0 Loss 0.4479 Accuracy 0.3299\n",
      "Epoch 86 Batch 50 Loss 0.4085 Accuracy 0.3291\n",
      "Epoch 86 Batch 100 Loss 0.4510 Accuracy 0.3247\n",
      "Epoch 86 Loss 0.4670 Accuracy 0.3228\n",
      "Epoch 87 Batch 0 Loss 0.3724 Accuracy 0.3299\n",
      "Epoch 87 Batch 50 Loss 0.3954 Accuracy 0.3283\n",
      "Epoch 87 Batch 100 Loss 0.4358 Accuracy 0.3249\n",
      "Epoch 87 Loss 0.4565 Accuracy 0.3227\n",
      "Epoch 88 Batch 0 Loss 0.3878 Accuracy 0.3420\n",
      "Epoch 88 Batch 50 Loss 0.4128 Accuracy 0.3263\n",
      "Epoch 88 Batch 100 Loss 0.4464 Accuracy 0.3243\n",
      "Epoch 88 Loss 0.4622 Accuracy 0.3226\n",
      "Epoch 89 Batch 0 Loss 0.4682 Accuracy 0.3021\n",
      "Epoch 89 Batch 50 Loss 0.4026 Accuracy 0.3308\n",
      "Epoch 89 Batch 100 Loss 0.4473 Accuracy 0.3245\n",
      "Epoch 89 Loss 0.4613 Accuracy 0.3235\n",
      "Epoch 90 Batch 0 Loss 0.3481 Accuracy 0.3264\n",
      "Epoch 90 Batch 50 Loss 0.3966 Accuracy 0.3300\n",
      "Epoch 90 Batch 100 Loss 0.4377 Accuracy 0.3247\n",
      "Epoch 90 Loss 0.4578 Accuracy 0.3229\n",
      "Epoch 91 Batch 0 Loss 0.3783 Accuracy 0.3472\n",
      "Epoch 91 Batch 50 Loss 0.3998 Accuracy 0.3284\n",
      "Epoch 91 Batch 100 Loss 0.4404 Accuracy 0.3242\n",
      "Epoch 91 Loss 0.4566 Accuracy 0.3226\n",
      "Epoch 92 Batch 0 Loss 0.3574 Accuracy 0.3281\n",
      "Epoch 92 Batch 50 Loss 0.4035 Accuracy 0.3273\n",
      "Epoch 92 Batch 100 Loss 0.4353 Accuracy 0.3254\n",
      "Epoch 92 Loss 0.4536 Accuracy 0.3227\n",
      "Epoch 93 Batch 0 Loss 0.2992 Accuracy 0.3663\n",
      "Epoch 93 Batch 50 Loss 0.4075 Accuracy 0.3270\n",
      "Epoch 93 Batch 100 Loss 0.4383 Accuracy 0.3248\n",
      "Epoch 93 Loss 0.4544 Accuracy 0.3223\n",
      "Epoch 94 Batch 0 Loss 0.2883 Accuracy 0.3611\n",
      "Epoch 94 Batch 50 Loss 0.3868 Accuracy 0.3305\n",
      "Epoch 94 Batch 100 Loss 0.4268 Accuracy 0.3257\n",
      "Epoch 94 Loss 0.4465 Accuracy 0.3235\n",
      "Epoch 95 Batch 0 Loss 0.3838 Accuracy 0.3368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 Batch 50 Loss 0.3855 Accuracy 0.3297\n",
      "Epoch 95 Batch 100 Loss 0.4217 Accuracy 0.3268\n",
      "Epoch 95 Loss 0.4422 Accuracy 0.3243\n",
      "Epoch 96 Batch 0 Loss 0.3124 Accuracy 0.3351\n",
      "Epoch 96 Batch 50 Loss 0.3837 Accuracy 0.3301\n",
      "Epoch 96 Batch 100 Loss 0.4339 Accuracy 0.3245\n",
      "Epoch 96 Loss 0.4476 Accuracy 0.3237\n",
      "Epoch 97 Batch 0 Loss 0.3470 Accuracy 0.3542\n",
      "Epoch 97 Batch 50 Loss 0.3850 Accuracy 0.3319\n",
      "Epoch 97 Batch 100 Loss 0.4218 Accuracy 0.3274\n",
      "Epoch 97 Loss 0.4414 Accuracy 0.3246\n",
      "Epoch 98 Batch 0 Loss 0.3768 Accuracy 0.3281\n",
      "Epoch 98 Batch 50 Loss 0.3838 Accuracy 0.3317\n",
      "Epoch 98 Batch 100 Loss 0.4291 Accuracy 0.3261\n",
      "Epoch 98 Loss 0.4469 Accuracy 0.3234\n",
      "Epoch 99 Batch 0 Loss 0.4252 Accuracy 0.3108\n",
      "Epoch 99 Batch 50 Loss 0.3744 Accuracy 0.3324\n",
      "Epoch 99 Batch 100 Loss 0.4267 Accuracy 0.3250\n",
      "Epoch 99 Loss 0.4430 Accuracy 0.3232\n",
      "Epoch 100 Batch 0 Loss 0.3499 Accuracy 0.3385\n",
      "Epoch 100 Batch 50 Loss 0.3735 Accuracy 0.3347\n",
      "Epoch 100 Batch 100 Loss 0.4186 Accuracy 0.3269\n",
      "Epoch 100 Loss 0.4390 Accuracy 0.3241\n"
     ]
    }
   ],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "  \n",
    "  # add extra dimensions to add the padding\n",
    "  # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)\n",
    "\n",
    "for epoch in range(100):\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "  \n",
    "    for (batch, (inp, tar)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        train_step(inp, tar)\n",
    "        if batch % 50 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "              epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "    \n",
    "    print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: good morning.\n",
      "Predicted translation: ['<start>', 'с', 'добрым', 'утром']\n"
     ]
    }
   ],
   "source": [
    "def evaluate(inp_sentence):\n",
    "    start_token = [1]\n",
    "    end_token = [2]\n",
    "  \n",
    "    sentence = preprocess_sentence(inp_sentence)\n",
    "    inputs = [inp_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "    \n",
    "    encoder_input = tf.expand_dims(inputs, 0)\n",
    "  \n",
    "  # as the target is english, the first word to the transformer should be the\n",
    "  # english start token.\n",
    "    decoder_input = [1]\n",
    "    output = tf.expand_dims(decoder_input, 0)\n",
    "    \n",
    "    for i in range(max_length_targ):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "            encoder_input, output)\n",
    "  \n",
    "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "        predictions, attention_weights = transformer(encoder_input, \n",
    "                                                 output,\n",
    "                                                 False,\n",
    "                                                 enc_padding_mask,\n",
    "                                                 combined_mask,\n",
    "                                                 dec_padding_mask)\n",
    "    \n",
    "    # select the last word from the seq_len dimension\n",
    "        predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "    \n",
    "    # return the result if the predicted_id is equal to the end token\n",
    "        if predicted_id == targ_lang_tokenizer.word_index[\"<end>\"]:\n",
    "            return tf.squeeze(output, axis=0), attention_weights\n",
    "    \n",
    "    # concatentate the predicted_id to the output which is given to the decoder\n",
    "    # as its input.\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output, axis=0), attention_weights\n",
    "\n",
    "\n",
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "  \n",
    "    sentence = inp_lang_tokenizer.encode(sentence)\n",
    "  \n",
    "    attention = tf.squeeze(attention[layer], axis=0)\n",
    "  \n",
    "    for head in range(attention.shape[0]):\n",
    "        ax = fig.add_subplot(2, 4, head+1)\n",
    "\n",
    "        # plot the attention weights\n",
    "        ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "        fontdict = {'fontsize': 10}\n",
    "\n",
    "        ax.set_xticks(range(len(sentence)+2))\n",
    "        ax.set_yticks(range(len(result)))\n",
    "\n",
    "        ax.set_ylim(len(result)-1.5, -0.5)\n",
    "\n",
    "        ax.set_xticklabels(\n",
    "            ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'], \n",
    "            fontdict=fontdict, rotation=90)\n",
    "\n",
    "        ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n",
    "                            if i < tokenizer_en.vocab_size], \n",
    "                           fontdict=fontdict)\n",
    "\n",
    "        ax.set_xlabel('Head {}'.format(head+1))\n",
    "  \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def translate(sentence, plot=''):\n",
    "    result, attention_weights = evaluate(sentence)\n",
    "    predicted_sentence = ([targ_lang_tokenizer.index_word[i] for i in result.numpy()])  \n",
    "\n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Predicted translation: {}'.format(predicted_sentence))\n",
    "  \n",
    "    if plot:\n",
    "        plot_attention_weights(attention_weights, sentence, result, plot)\n",
    "        \n",
    "translate(\"good morning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
